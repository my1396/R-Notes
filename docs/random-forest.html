<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.1 Random Forest | A Minimal Book Example</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="4.1 Random Forest | A Minimal Book Example" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="github-repo" content="my1396/R-Notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.1 Random Forest | A Minimal Book Example" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

<meta name="author" content="John Doe" />


<meta name="date" content="2025-03-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="machine-learning.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #204a87; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #204a87; font-weight: bold; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #ce5c00; font-weight: bold; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a>
<ul>
<li class="chapter" data-level="1.1" data-path="usage.html"><a href="usage.html"><i class="fa fa-check"></i><b>1.1</b> Usage</a></li>
<li class="chapter" data-level="1.2" data-path="render-book.html"><a href="render-book.html"><i class="fa fa-check"></i><b>1.2</b> Render book</a></li>
<li class="chapter" data-level="1.3" data-path="preview-book.html"><a href="preview-book.html"><i class="fa fa-check"></i><b>1.3</b> Preview book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="rstudio.html"><a href="rstudio.html"><i class="fa fa-check"></i><b>2</b> Rstudio</a>
<ul>
<li class="chapter" data-level="2.1" data-path="dark-theme.html"><a href="dark-theme.html"><i class="fa fa-check"></i><b>2.1</b> Dark Theme</a></li>
<li class="chapter" data-level="2.2" data-path="packages-management.html"><a href="packages-management.html"><i class="fa fa-check"></i><b>2.2</b> Packages Management</a>
<ul>
<li class="chapter" data-level="" data-path="packages-management.html"><a href="packages-management.html#put-your-r-package-on-github"><i class="fa fa-check"></i>Put your R package on GitHub</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="knit-rmd.html"><a href="knit-rmd.html"><i class="fa fa-check"></i><b>3</b> Knit Rmd</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chunk-options.html"><a href="chunk-options.html"><i class="fa fa-check"></i><b>3.1</b> Chunk Options</a></li>
<li class="chapter" data-level="3.2" data-path="print-verbatim-r-code-chunks.html"><a href="print-verbatim-r-code-chunks.html"><i class="fa fa-check"></i><b>3.2</b> Print Verbatim R code chunks</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>4</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>4.1</b> Random Forest</a>
<ul>
<li class="chapter" data-level="" data-path="random-forest.html"><a href="random-forest.html#implementation-in-r"><i class="fa fa-check"></i>Implementation in R</a></li>
<li class="chapter" data-level="" data-path="random-forest.html"><a href="random-forest.html#imbalance-classification"><i class="fa fa-check"></i>Imbalance Classification</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Minimal Book Example</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-forest" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Random Forest<a href="random-forest.html#random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Averaging of independent trees</strong></p>
<p>The goal of bagging is to produce <span class="math inline">\(\boldsymbol{B}\)</span> separate training datasets that are independent of each other (typically ùêµ is in the hundreds). The model of interest (in this case classification and regression trees) is trained separately on each of these datasets, resulting in <span class="math inline">\(\boldsymbol{B}\)</span> different estimated ‚Äúmodels‚Äù. These are then averaged to produce a single, low-variance estimate.</p>
<p>Bagging is a general approach, but its most well-known application is in the random forest algorithm:</p>
<ol style="list-style-type: decimal">
<li>Construct <span class="math inline">\(\boldsymbol{B}\)</span> bootstrap samples by sampling cases from the original dataset with replacement (this results in <span class="math inline">\(\boldsymbol{B}\)</span> unique datasets that are similar to the original)</li>
<li>Fit a classification and regression tree to each sample, but randomly choose a subset of <span class="math inline">\(m\)</span> variables that can be used in the construction of that tree (this results in <span class="math inline">\(\boldsymbol{B}\)</span> unique trees that are fit to similar datasets using different sets of predictors)</li>
<li>For a given data-point, each of the <span class="math inline">\(\boldsymbol{B}\)</span> trees in the forest contributes a prediction or ‚Äúvote‚Äù, with the majority (or average) of these votes forming the random forest‚Äôs final prediction, <span class="math inline">\(\hat{y}_i\)</span></li>
</ol>
<p>A downside of both the CART and random forest algorithms (as well as many other algorithmic modeling approaches) is an <u>inability to clearly quantify the roles played by individual variables</u> in making predictions. However, the importance of individual variables in a random forest can still be expressed using a measure known as variable importance.</p>
<p>The random forest algorithm requires the following tuning parameters be specified in order to run:</p>
<ul>
<li><code>ntree</code> - the number of bagged samples, <span class="math inline">\(\boldsymbol{B}\)</span>, onto which trees will be grown</li>
<li><code>mtry</code> - the number of variables that are randomly chosen to be candidates at each split</li>
<li>Some sort of stopping criteria for individual trees, this can be:
<ul>
<li><code>nodesize</code>, which sets the minimum <u>size of terminal nodes</u>
<ul>
<li>larger <code>nodesize</code> leads to shallower trees</li>
<li>smaller node size allows for deeper, more complex trees</li>
</ul></li>
<li><code>maxnodes</code>, which sets the maximum <u>number of terminal nodes</u> an individual tree can have.</li>
</ul></li>
</ul>
<p><strong>Applications of Random Forest</strong></p>
<p>Some of the applications of Random Forest Algorithm are listed below:</p>
<ul>
<li>Banking: It predicts a loan applicant‚Äôs solvency. This helps lending institutions make a good decision on whether to give the customer loan or not. They are also being used to detect fraudsters.</li>
<li>Health Care: Health professionals use random forest systems to diagnose patients. Patients are diagnosed by assessing their previous medical history. Past medical records are reviewed to establish the proper dosage for the patients.</li>
<li>Stock Market: Financial analysts use it to identify potential markets for stocks. It also enables them to remember the behaviour of stocks.</li>
<li>E-Commerce: Through this system, e-commerce vendors can predict the preference of customers based on past consumption behaviour.</li>
</ul>
<p><strong>When to Avoid Using Random Forests?</strong></p>
<p>Random Forests Algorithms are not ideal in the following situations:</p>
<ul>
<li>Extrapolation: Random Forest regression is not ideal in the extrapolation of data. Unlike linear regression, which uses existing observations to estimate values beyond the observation range.</li>
<li>Sparse Data: Random Forest does not produce good results when the data is sparse. In this case, the subject of features and bootstrapped sample will have an invariant space. This will lead to unproductive spills, which will affect the outcome.</li>
</ul>
<p><strong>FAQ</strong></p>
<p>Q: Is RF a linear or non-linear model?<br />
A: RF can capture complex, non-linear relationships.</p>
<p>Q: Is RF sensitive to Imbalanced Data?<br />
A: It may perform poorly if the dataset is highly imbalanced like one class is significantly more frequent than another.</p>
<p>Q: What is the loss function?<br />
A: Entropy/gini or any other loss function you want.</p>
<p>Q: Difference btw RF and a linear model?<br />
A: A major difference is that a decision tree does not have ‚Äúparameters‚Äù, whereas the linear models need to create a functional form and find the optimal parameters.</p>
<div id="implementation-in-r" class="section level3 unnumbered hasAnchor">
<h3>Implementation in R<a href="random-forest.html#implementation-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><code>ranger</code> package offers a computation efficient function for RF.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="random-forest.html#cb33-1" tabindex="-1"></a>RF_ranger <span class="ot">&lt;-</span> <span class="fu">ranger</span>(<span class="at">formula =</span> formula, </span>
<span id="cb33-2"><a href="random-forest.html#cb33-2" tabindex="-1"></a>                    <span class="at">data =</span> data_before[idx,], </span>
<span id="cb33-3"><a href="random-forest.html#cb33-3" tabindex="-1"></a>                    <span class="at">probability =</span> T,</span>
<span id="cb33-4"><a href="random-forest.html#cb33-4" tabindex="-1"></a>                    <span class="at">importance =</span> <span class="st">&quot;permutation&quot;</span>, </span>
<span id="cb33-5"><a href="random-forest.html#cb33-5" tabindex="-1"></a>                    <span class="at">scale.permutation.importance =</span> <span class="cn">TRUE</span>,</span>
<span id="cb33-6"><a href="random-forest.html#cb33-6" tabindex="-1"></a>                    )</span>
<span id="cb33-7"><a href="random-forest.html#cb33-7" tabindex="-1"></a>    <span class="co"># print(RF_ranger)</span></span>
<span id="cb33-8"><a href="random-forest.html#cb33-8" tabindex="-1"></a>    </span>
<span id="cb33-9"><a href="random-forest.html#cb33-9" tabindex="-1"></a>rf.pred.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(RF_ranger, <span class="at">data=</span>data_before[<span class="sc">-</span>idx,])<span class="sc">$</span>predictions</span></code></pre></div>
<p>The hyperparameters <code>mtry</code>, <code>min.node.size</code> and <code>sample.fraction</code> determine the degree of randomness, and should be tuned.</p>
<ul>
<li><code>mtry</code>: Number of variables to possibly split at in each node in one tree. In plain language, it indicates how many predictor variables should be used in each tree.
<ul>
<li>Default is the (rounded down) square root of the number variables. Alternatively, a single argument function returning an integer, given the number of independent variables.</li>
<li>Range btw 1 to the number of predictors.</li>
<li>If all predictors are used, then this corresponds in fact to bagging.</li>
</ul></li>
<li><code>min.node.size</code>: The number of observations a terminal node should at least have.
<ul>
<li>Default 1 for classification, 5 for regression, 3 for survival, and 10 for probability. For classification, this can be a vector of class-specific values.</li>
<li>Range between 1 and 10</li>
</ul></li>
<li><code>sample.fraction</code>: Fraction of observations to be used in each tree. Default is 1 for sampling with replacement and 0.632 for sampling without replacement. For <u>classification</u>, this can be a vector of class-specific values.
<ul>
<li>Smaller fractions lead to greater diversity, and thus less correlated trees which often is desirable.</li>
<li>Range between 0.2 and 0.9</li>
</ul></li>
</ul>
<p>Q: How to tune hyperparameters?<br />
A: Check out <a href="https://mlr3.mlr-org.com"><code>mlr3</code> package</a>. <a href="https://r.geocompx.org/eco.html">Here</a> is an example.</p>
<hr />
</div>
<div id="imbalance-classification" class="section level3 unnumbered hasAnchor">
<h3>Imbalance Classification<a href="random-forest.html#imbalance-classification" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You can balance your random forests using case weights. Here‚Äôs a simple example:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="random-forest.html#cb34-1" tabindex="-1"></a><span class="fu">library</span>(ranger) <span class="co">#Best random forest implementation in R</span></span>
<span id="cb34-2"><a href="random-forest.html#cb34-2" tabindex="-1"></a></span>
<span id="cb34-3"><a href="random-forest.html#cb34-3" tabindex="-1"></a><span class="co">#Make a dataste</span></span>
<span id="cb34-4"><a href="random-forest.html#cb34-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">43</span>)</span>
<span id="cb34-5"><a href="random-forest.html#cb34-5" tabindex="-1"></a>nrow <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb34-6"><a href="random-forest.html#cb34-6" tabindex="-1"></a>ncol <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb34-7"><a href="random-forest.html#cb34-7" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(nrow <span class="sc">*</span> ncol), <span class="at">ncol=</span>ncol)</span>
<span id="cb34-8"><a href="random-forest.html#cb34-8" tabindex="-1"></a>CF <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(ncol)</span>
<span id="cb34-9"><a href="random-forest.html#cb34-9" tabindex="-1"></a>Y <span class="ot">&lt;-</span> (X <span class="sc">%*%</span> CF <span class="sc">+</span> <span class="fu">rnorm</span>(nrow))[,<span class="dv">1</span>]</span>
<span id="cb34-10"><a href="random-forest.html#cb34-10" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.integer</span>(Y <span class="sc">&gt;</span> <span class="fu">quantile</span>(Y, <span class="fl">0.90</span>))</span>
<span id="cb34-11"><a href="random-forest.html#cb34-11" tabindex="-1"></a><span class="fu">table</span>(Y)</span>
<span id="cb34-12"><a href="random-forest.html#cb34-12" tabindex="-1"></a></span>
<span id="cb34-13"><a href="random-forest.html#cb34-13" tabindex="-1"></a><span class="co">#Compute weights to balance the RF</span></span>
<span id="cb34-14"><a href="random-forest.html#cb34-14" tabindex="-1"></a>w <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">table</span>(Y)</span>
<span id="cb34-15"><a href="random-forest.html#cb34-15" tabindex="-1"></a>w <span class="ot">&lt;-</span> w<span class="sc">/</span><span class="fu">sum</span>(w)</span>
<span id="cb34-16"><a href="random-forest.html#cb34-16" tabindex="-1"></a>weights <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, nrow)</span>
<span id="cb34-17"><a href="random-forest.html#cb34-17" tabindex="-1"></a>weights[Y <span class="sc">==</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> w[<span class="st">&#39;0&#39;</span>]</span>
<span id="cb34-18"><a href="random-forest.html#cb34-18" tabindex="-1"></a>weights[Y <span class="sc">==</span> <span class="dv">1</span>] <span class="ot">&lt;-</span> w[<span class="st">&#39;1&#39;</span>]</span>
<span id="cb34-19"><a href="random-forest.html#cb34-19" tabindex="-1"></a><span class="fu">table</span>(weights, Y)</span>
<span id="cb34-20"><a href="random-forest.html#cb34-20" tabindex="-1"></a></span>
<span id="cb34-21"><a href="random-forest.html#cb34-21" tabindex="-1"></a><span class="co">#Fit the RF</span></span>
<span id="cb34-22"><a href="random-forest.html#cb34-22" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Y=</span><span class="fu">factor</span>(<span class="fu">ifelse</span>(Y<span class="sc">==</span><span class="dv">0</span>, <span class="st">&#39;no&#39;</span>, <span class="st">&#39;yes&#39;</span>)), X)</span>
<span id="cb34-23"><a href="random-forest.html#cb34-23" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">ranger</span>(Y<span class="sc">~</span>., data, <span class="at">case.weights=</span>weights)</span>
<span id="cb34-24"><a href="random-forest.html#cb34-24" tabindex="-1"></a><span class="fu">print</span>(model)</span></code></pre></div>
<p>Source: <a href="https://stats.stackexchange.com/a/287849" class="uri">https://stats.stackexchange.com/a/287849</a></p>
<hr />
<p><strong>References</strong>:</p>
<p><a href="https://remiller1450.github.io/m257s21/Lab10_Other_Models.html" class="uri">https://remiller1450.github.io/m257s21/Lab10_Other_Models.html</a></p>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="machine-learning.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "sky",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/my1396/R-Notes/edit/main/1000-MachineLearning.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub", "https://github.com/my1396/R-Notes/raw/main/1000-MachineLearning.Rmd"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
